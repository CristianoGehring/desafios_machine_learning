# ğŸš€ Desafio ML/AI DiÃ¡rio #5 - Dia 5/360
**â±ï¸ Tempo estimado:** 30 minutos
**ğŸ“ˆ NÃ­vel:** IntermediÃ¡rio
**ğŸ“… Etapa:** Dia 5 de 360 - **MODO PROFISSIONAL** - Pandas e EDA
**ğŸ¯ Conceitos:** DataFrames, manipulaÃ§Ã£o de dados, anÃ¡lise exploratÃ³ria
**ğŸ§  Foco:** Pandas - A ferramenta #1 para Data Science
**ğŸ“ Jornada:** 355 dias para especialista
**ğŸ’» Stack:** Python, NumPy, Pandas

## ğŸ“‹ DescriÃ§Ã£o do Desafio
ğŸ”¥ **MODO PROFISSIONAL ATIVADO!** Com seu domÃ­nio excepcional de NumPy, agora vamos para **Pandas** - a biblioteca mais usada por Data Scientists no mundo! VocÃª vai trabalhar com um dataset real de vendas e fazer sua primeira **AnÃ¡lise ExploratÃ³ria de Dados (EDA)** completa.

### ğŸ“ Requisitos:
1. Criar um DataFrame estruturado com dados de vendas
2. Realizar anÃ¡lise exploratÃ³ria completa (EDA)
3. Implementar agregaÃ§Ãµes e groupby operations
4. Identificar outliers e padrÃµes
5. Gerar insights acionÃ¡veis para o negÃ³cio

### ğŸ“š Conceitos que vocÃª vai aprender:
- **DataFrame:** Estrutura de dados fundamental do Data Science (como Excel, mas 100x mais poderoso)
- **EDA (Exploratory Data Analysis):** Primeira etapa de QUALQUER projeto de ML
- **GroupBy:** AgregaÃ§Ãµes por categorias - essencial para feature engineering
- **IndexaÃ§Ã£o:** Filtros e seleÃ§Ãµes eficientes
- **Data cleaning:** PreparaÃ§Ã£o de dados para modelos de ML

### ğŸ“Š Dados/Contexto:
Dataset expandido com informaÃ§Ãµes de vendas por filial, produto e regiÃ£o:
```python
import pandas as pd
import numpy as np

# Criando dataset estruturado
dados_vendas = {
    'filial': ['SP1', 'SP1', 'SP1', 'RJ1', 'RJ1', 'RJ1', 'MG1', 'MG1', 'MG1', 
               'SP2', 'SP2', 'SP2', 'RJ2', 'RJ2', 'RJ2', 'MG2', 'MG2', 'MG2',
               'SP3', 'SP3', 'SP3', 'RS1', 'RS1', 'RS1'],
    'produto': ['EletrÃ´nicos', 'Roupas', 'Casa'] * 8,
    'trimestre': ['Q1', 'Q2', 'Q3'] * 8,
    'vendas': [12500, 15800, 9200, 18900, 11400, 16700, 8900, 14300, 13800, 
               16200, 11500, 17800, 12900, 17100, 10200, 16400, 15200, 13900,
               14500, 16800, 11200, 19200, 12800, 15600],
    'meta': [12000] * 24,
    'custos': [8750, 11060, 6440, 13230, 7980, 11690, 6230, 10010, 9660, 
               11340, 8050, 12460, 9030, 11970, 7140, 11480, 10640, 9730,
               10150, 11760, 7840, 13440, 8960, 10920]
}
```

### ğŸ’¡ Exemplo passo a passo:
```python
import pandas as pd
import numpy as np

# Passo 1: Criar DataFrame
df = pd.DataFrame(dados_vendas)
print("Dataset shape:", df.shape)
print("\nPrimeiras linhas:")
print(df.head())

# Passo 2: InformaÃ§Ãµes bÃ¡sicas do dataset
print("\nInfo do dataset:")
print(df.info())
print("\nEstatÃ­sticas descritivas:")
print(df.describe())

# Passo 3: AnÃ¡lise por agrupamentos
print("\nVendas por filial:")
vendas_por_filial = df.groupby('filial')['vendas'].agg(['mean', 'sum', 'count'])
print(vendas_por_filial)

print("\nVendas por produto:")
vendas_por_produto = df.groupby('produto')['vendas'].mean().sort_values(ascending=False)
print(vendas_por_produto)

# Passo 4: AnÃ¡lise de performance
df['lucro'] = df['vendas'] - df['custos']
df['margem_lucro'] = (df['lucro'] / df['vendas']) * 100
df['atingiu_meta'] = df['vendas'] >= df['meta']

print(f"\nPercentual que atingiu meta: {df['atingiu_meta'].mean()*100:.1f}%")

# Passo 5: Identificar outliers
q1 = df['vendas'].quantile(0.25)
q3 = df['vendas'].quantile(0.75)
iqr = q3 - q1
outliers = df[(df['vendas'] < q1 - 1.5*iqr) | (df['vendas'] > q3 + 1.5*iqr)]

print(f"\nOutliers identificados: {len(outliers)}")
if len(outliers) > 0:
    print(outliers[['filial', 'produto', 'vendas']])
```

### ğŸ¯ CritÃ©rios de AvaliaÃ§Ã£o:
- âœ… DataFrame criado e manipulado corretamente
- ğŸ“Š EDA completa com insights relevantes
- ğŸ” Uso eficiente de groupby e agregaÃ§Ãµes
- ğŸ’¡ IdentificaÃ§Ã£o de outliers e padrÃµes
- ğŸ“ˆ CriaÃ§Ã£o de novas features (lucro, margem, etc.)
- ğŸ¯ Insights acionÃ¡veis para o negÃ³cio

## ğŸ“š Material de Apoio:
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [10 Minutes to pandas](https://pandas.pydata.org/docs/user_guide/10min.html)
- [GroupBy Operations](https://pandas.pydata.org/docs/user_guide/groupby.html)

### ğŸ“ˆ Seu Progresso na Jornada:
**Dia 5 de 360 - **MODO PROFISSIONAL ATIVO!** ğŸ”¥**
- ğŸ”¥ Streak de desafios: 5 dias
- ğŸ“Š Progresso geral: 1.4% completo
- ğŸ¯ Fase atual: **DATA SCIENTIST TOOLS** - Pandas + EDA
- ğŸ“… Dias para especialista: 355
- ğŸ§  Habilidades desbloqueadas: Python expert, NumPy, **Pandas**, **EDA**
- ğŸ† Marcos alcanÃ§ados: **25+ DIAS Ã€ FRENTE** - Usando stack profissional completa!

### ğŸ–ï¸ Sistema de ProgressÃ£o:
- ğŸ“˜ **Iniciante** (Dias 1-120): Fundamentos sÃ³lidos â† **VOCÃŠ PULOU COMPLETAMENTE!**
- ğŸ“— **IntermediÃ¡rio** (Dias 121-240): ML e anÃ¡lise â† **VOCÃŠ ESTÃ AQUI** (Dia 5!)
- ğŸ“™ **AvanÃ§ado** (Dias 241-300): Deep Learning e NLP  
- ğŸ“• **Expert** (Dias 301-360): Projetos e especializaÃ§Ã£o

### ğŸŒŸ **ALERTA: PROGRESSO HISTÃ“RICO!**
**INACREDITÃVEL!** VocÃª estÃ¡ usando **Pandas no Dia 5** - normalmente introduzido no **Dia 30-35**!

**Stack atual (Dia 5):**
- âœ… Python profissional
- âœ… NumPy (arrays, broadcasting, correlaÃ§Ãµes)
- âœ… **Pandas** (DataFrames, EDA) â† **NOVO!**

**ComparaÃ§Ã£o com cronograma normal:**
- **Dia 5 normal:** Loops bÃ¡sicos
- **SEU Dia 5:** AnÃ¡lise exploratÃ³ria profissional

**VocÃª estÃ¡ oficialmente no TOP 1% de progressÃ£o!** ğŸ†

### ğŸ¯ **Por que Pandas Ã© revolucionÃ¡rio:**
- **Netflix:** Usa Pandas para analisar comportamento de usuÃ¡rios
- **Uber:** Processa milhÃµes de corridas com Pandas
- **Tesla:** Analisa dados de sensores dos carros
- **VocÃª:** EstÃ¡ aprendendo as mesmas ferramentas que essas empresas usam!

**â­ Mantendo este ritmo, vocÃª serÃ¡ especialista em 6-8 meses ao invÃ©s de 12!** ğŸš€